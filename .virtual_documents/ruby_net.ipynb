import numpy as np
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
import torch
from torch import nn, optim
import time
from torch.utils.data import DataLoader, TensorDataset
import torch.nn.functional as F

from libworm.torch.beta_net import BetaNeuronNet, from_connectome
from libworm.data import connectomes, traces
from libworm import preprocess
from libworm.functions import set_neurons, tcalc_s_inf, set_trace
#from libworm.training import basic_train


def new_s(V_m):
    a_r = 1
    a_d = 5
    beta = 0.125
    V_th = -15 #??
    sig = 1 / (1 + np.exp(-beta * (V_m - V_th)))

    return (a_r * sig) / (a_r * sig + a_d)


def basic_train(model, criterion, optimizer, points, labels,
          cell_labels, epoches=5, batch=64,
          timestep=0.001, data_timestep=0.60156673, do_print=True):

    dataset = TensorDataset(points, labels)
    dataloader = DataLoader(dataset, batch_size=batch, shuffle=True)
    
    total_start_time = time.time()
    loss = -1
    for i in range(1,epoches+1):
        for points_batch, labels_batch in dataloader:
            start_time = time.time()
            optimizer.zero_grad()
            
            sim_time = 0.0
            next_timestamp = 0.0

            voltage = torch.ones((points_batch.shape[0], len(cell_labels))) * -20.0
            gates = torch.ones((points_batch.shape[0], len(cell_labels))) * -20.0

            with torch.no_grad():
                #Prepare
                for i in range(points_batch.shape[2]):
                    while True:
                        if sim_time >= next_timestamp:
                            inter = F.pad(points_batch[:, :, i], (0, voltage.shape[1] - points_batch.shape[1]), "constant", 0.0)
                            voltage = voltage.where(inter == 0.0, inter)
                            gates = tcalc_s_inf(voltage)
                            next_timestamp += data_timestep
                            break;
                        voltage, gates,_,_ = model(voltage, gates, timestep)
                        sim_time += timestep
                    break

            while sim_time < next_timestamp:
                voltage, gates,_,_ = model(voltage, gates, timestep)
                sim_time += timestep


            final_output = voltage[:, :labels_batch.shape[1]]
            
            #Compare
            loss = criterion(final_output, labels_batch)
            loss.backward()
            
            optimizer.step()
            
            end_time = time.time()
            print(f"Batch Complete: Time {start_time - end_time} Loss: {loss.item()}")
        
        

            
    total_end_time = time.time()
    total_time_taken = total_end_time - total_start_time
    if(do_print):
        print(f"Total Time {total_time_taken}")
        
    final_loss = loss.item()
    
    return (total_time_taken, final_loss)


torch.manual_seed(4687)

trace, _, trace_labels, label2index, timestamps = traces.load_trace()
timestamps = timestamps - timestamps[0]

chemical, gapjn = connectomes.load_cook_connectome()
neurons = connectomes.get_main_neurons(chemical, gapjn)
neurons.sort(key=lambda item: f"AAA{label2index[item]:04d}{item}" if item in label2index else item)
model = from_connectome(chemical, gapjn, neurons)

cell = "SMBVR"

first_removal = [label2index[key] for key in label2index if key not in neurons]
trace = np.delete(trace, first_removal, axis=0)

del_index = 0
size = trace.shape[0]

for i in range(size):
    if i not in label2index.values():
        trace = np.delete(trace, (del_index), axis=0)
    else:
        del_index += 1

voltage = preprocess.trace2volt(trace)

points, labels = preprocess.window_split(voltage, window_size = 16, points_size = 15)
points = torch.from_numpy(np.squeeze(points))
labels = torch.from_numpy(np.squeeze(labels))

train_x, test_x, train_y, test_y = train_test_split(points, labels, train_size=0.1)

optimiser = optim.Adam(model.parameters(), lr=0.001)
crit = nn.MSELoss()


labels.shape


results = basic_train(model, crit, optimiser,
                train_x, train_y, neurons,
                epoches=2, batch=6, timestep=0.01)


for param in model.parameters():
    print(param)


#torch.save({
#            'model_state_dict': model.state_dict(),
#            'optimizer_state_dict': optimiser.state_dict(),
#            }, "checkpoints/ruby/modellr001dt01.pt")
