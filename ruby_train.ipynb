{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94c67ce-26a0-4e57-8721-086e04554b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import time\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from libworm.torch.beta_net import BetaNeuronNet, from_connectome\n",
    "from libworm.data import connectomes, traces\n",
    "from libworm import preprocess\n",
    "from libworm.functions import set_neurons, tcalc_s_inf, set_trace\n",
    "#from libworm.training import basic_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131ef908-421e-4c24-8529-68bb6e4735e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_s(V_m):\n",
    "    a_r = 1\n",
    "    a_d = 5\n",
    "    beta = 0.125\n",
    "    V_th = -15 #??\n",
    "    sig = 1 / (1 + np.exp(-beta * (V_m - V_th)))\n",
    "\n",
    "    return (a_r * sig) / (a_r * sig + a_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e20a32f-7b00-4b1f-a9ea-1e02bdee5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_train(model, criterion, optimizer, points, labels,\n",
    "          cell_labels, epoches=5, batch=64,\n",
    "          timestep=0.001, data_timestep=0.60156673, do_print=True):\n",
    "\n",
    "    dataset = TensorDataset(points, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch, shuffle=True)\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    loss = -1\n",
    "    for i in range(1,epoches+1):\n",
    "        for points_batch, labels_batch in dataloader:\n",
    "            start_time = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            sim_time = 0.0\n",
    "            next_timestamp = 0.0\n",
    "\n",
    "            voltage = torch.ones((points_batch.shape[0], len(cell_labels))) * -20.0\n",
    "            gates = torch.ones((points_batch.shape[0], len(cell_labels))) * -20.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                #Prepare\n",
    "                for i in range(points_batch.shape[2]):\n",
    "                    while True:\n",
    "                        if sim_time >= next_timestamp:\n",
    "                            inter = F.pad(points_batch[:, :, i], (0, voltage.shape[1] - points_batch.shape[1]), \"constant\", 0.0)\n",
    "                            voltage = voltage.where(inter == 0.0, inter)\n",
    "                            gates = tcalc_s_inf(voltage)\n",
    "                            next_timestamp += data_timestep\n",
    "                            break;\n",
    "                        voltage, gates,_,_ = model(voltage, gates, timestep)\n",
    "                        sim_time += timestep\n",
    "                    break\n",
    "\n",
    "            while sim_time < next_timestamp:\n",
    "                voltage, gates,_,_ = model(voltage, gates, timestep)\n",
    "                sim_time += timestep\n",
    "\n",
    "\n",
    "            final_output = voltage[:, :labels_batch.shape[1]]\n",
    "            \n",
    "            #Compare\n",
    "            loss = criterion(final_output, labels_batch)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            end_time = time.time()\n",
    "            print(f\"Batch Complete: Time {start_time - end_time} Loss: {loss.item()}\")\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "    total_end_time = time.time()\n",
    "    total_time_taken = total_end_time - total_start_time\n",
    "    if(do_print):\n",
    "        print(f\"Total Time {total_time_taken}\")\n",
    "        \n",
    "    final_loss = loss.item()\n",
    "    \n",
    "    return (total_time_taken, final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac04bfc-a6d6-4846-92a5-1a531429ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This process is likely currently wrong\n",
    "\"\"\"\n",
    "\n",
    "torch.manual_seed(4687)\n",
    "\n",
    "trace, _, trace_labels, label2index, timestamps = traces.load_trace()\n",
    "timestamps = timestamps - timestamps[0]\n",
    "\n",
    "chemical, gapjn = connectomes.load_cook_connectome()\n",
    "neurons = connectomes.get_main_neurons(chemical, gapjn)\n",
    "neurons.sort(key=lambda item: f\"AAA{label2index[item]:04d}{item}\" if item in label2index else item)\n",
    "model = from_connectome(chemical, gapjn, neurons)\n",
    "\n",
    "cell = \"SMBVR\"\n",
    "\n",
    "first_removal = [label2index[key] for key in label2index if key not in neurons]\n",
    "trace = np.delete(trace, first_removal, axis=0)\n",
    "\n",
    "del_index = 0\n",
    "size = trace.shape[0]\n",
    "\n",
    "for i in range(size):\n",
    "    if i not in label2index.values():\n",
    "        trace = np.delete(trace, (del_index), axis=0)\n",
    "    else:\n",
    "        del_index += 1\n",
    "\n",
    "voltage = preprocess.trace2volt(trace)\n",
    "\n",
    "points, labels = preprocess.window_split(voltage, window_size = 16, points_size = 15)\n",
    "points = torch.from_numpy(np.squeeze(points))\n",
    "labels = torch.from_numpy(np.squeeze(labels))\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(points, labels, train_size=0.1)\n",
    "\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
    "crit = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d48d65-82ca-494e-bca1-184a0000a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1584, 101])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674579a6-7881-41ee-9589-3ea97315ecd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Complete: Time -0.23248744010925293 Loss: 653.1237154894314\n",
      "Batch Complete: Time -0.17736506462097168 Loss: 649.5425761881489\n",
      "Batch Complete: Time -0.17402935028076172 Loss: 643.2438723141395\n",
      "Batch Complete: Time -0.16890311241149902 Loss: 642.9759388654593\n",
      "Batch Complete: Time -0.1834876537322998 Loss: 643.6777355323189\n",
      "Batch Complete: Time -0.18149089813232422 Loss: 643.2411870793468\n",
      "Batch Complete: Time -0.18052148818969727 Loss: 640.8189611675426\n",
      "Batch Complete: Time -0.16945862770080566 Loss: 649.7647942528965\n",
      "Batch Complete: Time -0.18130064010620117 Loss: 648.4245876210554\n",
      "Batch Complete: Time -0.17880678176879883 Loss: 638.1279731361715\n",
      "Batch Complete: Time -0.1853346824645996 Loss: 638.0032292845351\n",
      "Batch Complete: Time -0.174424409866333 Loss: 642.9300634256706\n",
      "Batch Complete: Time -0.18352150917053223 Loss: 647.1594580609232\n",
      "Batch Complete: Time -0.17026662826538086 Loss: 641.6702697839244\n",
      "Batch Complete: Time -0.19524168968200684 Loss: 643.5961697616516\n",
      "Batch Complete: Time -0.18852806091308594 Loss: 644.5722263969247\n",
      "Batch Complete: Time -0.19337129592895508 Loss: 647.0992759398231\n",
      "Batch Complete: Time -0.17734527587890625 Loss: 646.8370742274732\n",
      "Batch Complete: Time -0.1826457977294922 Loss: 643.224213386258\n",
      "Batch Complete: Time -0.17955708503723145 Loss: 649.9109932519709\n",
      "Batch Complete: Time -0.20345640182495117 Loss: 644.9000500678936\n",
      "Batch Complete: Time -0.22017645835876465 Loss: 640.6956679249254\n",
      "Batch Complete: Time -0.22313880920410156 Loss: 640.4845424001469\n",
      "Batch Complete: Time -0.1695566177368164 Loss: 632.826887335308\n",
      "Batch Complete: Time -0.31818366050720215 Loss: 645.3468484969686\n",
      "Batch Complete: Time -0.18381023406982422 Loss: 640.4067606616018\n",
      "Batch Complete: Time -0.16826510429382324 Loss: 662.7724832872552\n",
      "Batch Complete: Time -0.26168394088745117 Loss: 651.5117475145623\n",
      "Batch Complete: Time -0.19944071769714355 Loss: 640.3774832861069\n",
      "Batch Complete: Time -0.40749192237854004 Loss: 645.2608254562304\n",
      "Batch Complete: Time -0.24216675758361816 Loss: 648.2448242582254\n",
      "Batch Complete: Time -0.1688539981842041 Loss: 635.875667032321\n",
      "Batch Complete: Time -0.19406414031982422 Loss: 639.4729857313018\n",
      "Batch Complete: Time -0.1785283088684082 Loss: 646.1038636595348\n",
      "Batch Complete: Time -0.1946122646331787 Loss: 639.9138397521681\n",
      "Batch Complete: Time -0.1951758861541748 Loss: 643.2218457644329\n",
      "Batch Complete: Time -0.23415255546569824 Loss: 644.1371759751759\n",
      "Batch Complete: Time -0.3092074394226074 Loss: 645.1388157278201\n",
      "Batch Complete: Time -0.2701418399810791 Loss: 645.3247771974841\n",
      "Batch Complete: Time -0.1685643196105957 Loss: 648.7904875657854\n",
      "Batch Complete: Time -0.1744997501373291 Loss: 641.9512923717937\n",
      "Batch Complete: Time -0.16520452499389648 Loss: 635.3961181893856\n",
      "Batch Complete: Time -0.20299386978149414 Loss: 635.8863615103164\n",
      "Batch Complete: Time -0.17778730392456055 Loss: 637.9727751492875\n",
      "Batch Complete: Time -0.2091217041015625 Loss: 638.570413968507\n",
      "Batch Complete: Time -0.2195754051208496 Loss: 642.0404683431393\n",
      "Batch Complete: Time -0.20328068733215332 Loss: 644.7422985460798\n",
      "Batch Complete: Time -0.19336867332458496 Loss: 646.3852940997704\n",
      "Batch Complete: Time -0.20322489738464355 Loss: 636.066781452703\n",
      "Batch Complete: Time -0.19165349006652832 Loss: 642.6706794017362\n",
      "Batch Complete: Time -0.18193674087524414 Loss: 637.9968743580486\n",
      "Batch Complete: Time -0.1858978271484375 Loss: 638.5540450201769\n",
      "Batch Complete: Time -0.22328925132751465 Loss: 636.9396281965072\n",
      "Batch Complete: Time -0.09969162940979004 Loss: 659.4638960161519\n",
      "Total Time 10.81939959526062\n"
     ]
    }
   ],
   "source": [
    "results = basic_train(model, crit, optimiser,\n",
    "                train_x, train_y, neurons,\n",
    "                epoches=2, batch=6, timestep=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee5d71c3-9be3-42cb-a17c-ecfb2bd3fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([10.0543, 10.0545, 10.0543, 10.0060, 10.0543, 10.0543, 10.0541, 10.0542,\n",
      "        10.0541, 10.0542, 10.0060,  9.9940, 10.0542,  9.9940, 10.0541, 10.0542,\n",
      "         9.9940,  9.9940, 10.0547, 10.0543, 10.0194, 10.0541, 10.0544, 10.0547,\n",
      "        10.0541, 10.0060, 10.0541, 10.0060, 10.0541, 10.0547,  9.9940, 10.0528,\n",
      "         9.9940,  9.9940, 10.0542, 10.0539, 10.0060, 10.0541, 10.0528, 10.0540,\n",
      "        10.0060, 10.0541, 10.0541, 10.0544, 10.0060, 10.0060, 10.0060, 10.0543,\n",
      "        10.0540, 10.0546, 10.0529, 10.0541, 10.0540, 10.0543, 10.0539, 10.0540,\n",
      "        10.0542, 10.0530, 10.0543, 10.0529, 10.0542, 10.0529, 10.0542, 10.0542,\n",
      "        10.0060, 10.0529, 10.0541, 10.0544, 10.0541, 10.0541, 10.0541, 10.0543,\n",
      "        10.0544, 10.0543, 10.0542, 10.0060, 10.0544, 10.0060, 10.0540, 10.0543,\n",
      "        10.0543, 10.0060, 10.0060, 10.0546, 10.0544, 10.0547, 10.0547,  9.9940,\n",
      "        10.0543,  9.9940, 10.0541, 10.0544, 10.0543, 10.0545,  9.9940, 10.0541,\n",
      "        10.0527, 10.0542, 10.0060, 10.0060, 10.0527, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000,\n",
      "        10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000, 10.0000],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-35.0543, -35.0546, -35.0543, -35.0060, -35.0543, -35.0544, -35.0541,\n",
      "        -35.0543, -35.0541, -35.0542, -35.0060, -35.0527, -35.0542, -34.9940,\n",
      "        -35.0542, -35.0542, -35.0060, -34.9940, -35.0549, -35.0543, -35.0152,\n",
      "        -35.0542, -35.0545, -35.0549, -35.0541, -35.0060, -35.0542, -35.0528,\n",
      "        -35.0541, -35.0549, -34.9940, -35.0528, -34.9940, -35.0060, -35.0543,\n",
      "        -35.0540, -35.0060, -35.0541, -35.0060, -35.0541, -35.0525, -35.0541,\n",
      "        -35.0541, -35.0544, -35.0527, -35.0528, -35.0527, -35.0543, -35.0540,\n",
      "        -35.0547, -35.0529, -35.0541, -35.0540, -35.0543, -35.0540, -35.0541,\n",
      "        -35.0542, -34.9940, -35.0543, -35.0060, -35.0542, -35.0530, -35.0542,\n",
      "        -35.0543, -34.9940, -35.0530, -35.0542, -35.0545, -35.0541, -35.0541,\n",
      "        -35.0541, -35.0544, -35.0545, -35.0543, -35.0542, -35.0060, -35.0545,\n",
      "        -35.0060, -35.0541, -35.0543, -35.0544, -34.9940, -35.0528, -35.0547,\n",
      "        -35.0545, -35.0548, -35.0549, -34.9940, -35.0544, -34.9940, -35.0542,\n",
      "        -35.0545, -35.0544, -35.0545, -35.0060, -35.0541, -34.9940, -35.0542,\n",
      "        -34.9940, -35.0060, -35.0060, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000,\n",
      "        -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000, -35.0000],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-5.4647e-02, -5.4676e-02, -5.3956e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-5.5138e-02, -5.5134e-02, -5.4797e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-5.4361e-02, -5.4314e-02, -5.3611e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.0000e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.0000e+02]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-5.4095e-02, -5.4252e-02, -5.3436e-02, -5.3081e-02, -4.3284e-02,\n",
      "        -4.9397e-02, -4.5000e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.5000e+01,  0.0000e+00,\n",
      "        -4.5000e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -4.5000e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -4.5000e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -4.5000e+01, -4.5000e+01,\n",
      "        -4.5000e+01, -4.5000e+01, -4.5000e+01, -4.5000e+01,  0.0000e+00,\n",
      "        -4.5000e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -4.5000e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -4.5000e+01, -4.5000e+01, -4.5000e+01,\n",
      "        -4.5000e+01, -4.5000e+01, -4.5000e+01, -4.5000e+01, -4.5000e+01,\n",
      "        -4.5000e+01, -4.5000e+01, -4.5000e+01, -4.5000e+01, -4.5000e+01],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.0497e-03, -1.0534e-03, -6.4103e-03,  ..., -5.4667e-02,\n",
      "         -5.4667e-02, -5.4667e-02],\n",
      "        [ 5.5791e-02,  5.5907e-02,  2.0245e-02,  ..., -5.5302e-02,\n",
      "         -5.5302e-02, -5.5302e-02],\n",
      "        [-5.0856e-04, -5.0952e-04, -6.2992e-03,  ..., -5.4583e-02,\n",
      "         -5.4583e-02, -5.4583e-02],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          1.0000e+02,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.0000e+02,\n",
      "          0.0000e+00,  1.0000e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          1.0000e+02,  0.0000e+00]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7882f007-1dbd-4f38-b31d-fd31e4a74b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save({\n",
    "#            'model_state_dict': model.state_dict(),\n",
    "#            'optimizer_state_dict': optimiser.state_dict(),\n",
    "#            }, \"checkpoints/ruby/modellr001dt01.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
