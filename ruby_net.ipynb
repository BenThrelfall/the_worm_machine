{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94c67ce-26a0-4e57-8721-086e04554b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import time\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from libworm.torch.beta_net import BetaNeuronNet, from_connectome\n",
    "from libworm.data import connectomes, traces\n",
    "from libworm import preprocess\n",
    "from libworm.functions import set_neurons, tcalc_s_inf, set_trace\n",
    "from libworm.training import basic_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131ef908-421e-4c24-8529-68bb6e4735e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_s(V_m):\n",
    "    a_r = 1\n",
    "    a_d = 5\n",
    "    beta = 0.125\n",
    "    V_th = -15 #??\n",
    "    sig = 1 / (1 + np.exp(-beta * (V_m - V_th)))\n",
    "\n",
    "    return (a_r * sig) / (a_r * sig + a_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a16c56-6bed-4001-bc0f-530940cc84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "V = torch.from_numpy(np.array([40.0, -40.0]))\n",
    "s = torch.from_numpy(np.array([new_s(40.0), new_s(-40.0)]))\n",
    "G_leak = np.array([10.0 for V_m in V])\n",
    "E_leak = np.array([-35.0 for V_m in V])\n",
    "G_syn = np.array([[0.0, 50.0], [80.0, 0.0]])\n",
    "E_syn = np.array([0.0 for V_m in V])\n",
    "G_gap = np.array([[0.0, 100.0], [100.0, 0.0]])\n",
    "\n",
    "net = BetaNeuronNet(G_leak, E_leak, G_syn, E_syn, G_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c252c2e-dcb6-49a2-a23a-29c6afd7714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, points, labels,\n",
    "          cell_labels, epoches=5, batch=64,\n",
    "          timestep=0.001, data_timestep=0.60156673, do_print=True):\n",
    "\n",
    "    dataset = TensorDataset(points, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch, shuffle=True)\n",
    "    \n",
    "    total_start_time = time.time()\n",
    "    loss = -1\n",
    "    for i in range(1,epoches+1):\n",
    "        for points_batch, labels_batch in dataloader:\n",
    "            start_time = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            sim_time = 0.0\n",
    "            next_timestamp = 0.0\n",
    "\n",
    "            voltage = torch.ones((points_batch.shape[0], len(cell_labels))) * -20.0\n",
    "            gates = torch.ones((points_batch.shape[0], len(cell_labels))) * -20.0\n",
    "\n",
    "            \n",
    "            #Prepare\n",
    "            for i in range(points_batch.shape[2]):\n",
    "                while True:\n",
    "                    if sim_time >= next_timestamp:\n",
    "                        inter = F.pad(points_batch[:, :, i], (0, voltage.shape[1] - points_batch.shape[1]), \"constant\", 0.0)\n",
    "                        voltage = voltage.where(inter == 0.0, inter)\n",
    "                        gates = tcalc_s_inf(voltage)\n",
    "                        next_timestamp += data_timestep\n",
    "                        break;\n",
    "                    voltage, gates,_,_ = model(voltage, gates, timestep)\n",
    "                    sim_time += timestep\n",
    "\n",
    "            while sim_time < next_timestamp:\n",
    "                voltage, gates,_,_ = model(voltage, gates, timestep)\n",
    "                sim_time += timestep\n",
    "\n",
    "\n",
    "            final_output = voltage[:, :labels_batch.shape[1]]\n",
    "            \n",
    "            #Compare\n",
    "            loss = criterion(final_output, labels_batch)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            end_time = time.time()\n",
    "            print(f\"Batch Complete: Time {start_time - end_time} Loss: {loss.item()}\")\n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "    total_end_time = time.time()\n",
    "    total_time_taken = total_end_time - total_start_time\n",
    "    if(do_print):\n",
    "        print(f\"Total Time {total_time_taken}\")\n",
    "        \n",
    "    final_loss = loss.item()\n",
    "    \n",
    "    return (total_time_taken, final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ac04bfc-a6d6-4846-92a5-1a531429ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(4687)\n",
    "\n",
    "trace, _, trace_labels, label2index, timestamps = traces.load_trace()\n",
    "timestamps = timestamps - timestamps[0]\n",
    "\n",
    "chemical, gapjn = connectomes.load_cook_connectome()\n",
    "neurons = connectomes.get_main_neurons(chemical, gapjn)\n",
    "neurons.sort(key=lambda item: f\"AAA{label2index[item]:04d}{item}\" if item in label2index else item)\n",
    "model = from_connectome(chemical, gapjn, neurons)\n",
    "\n",
    "cell = \"SMBVR\"\n",
    "\n",
    "first_removal = [label2index[key] for key in label2index if key not in neurons]\n",
    "trace = np.delete(trace, first_removal, axis=0)\n",
    "\n",
    "del_index = 0\n",
    "size = trace.shape[0]\n",
    "\n",
    "for i in range(size):\n",
    "    if i not in label2index.values():\n",
    "        trace = np.delete(trace, (del_index), axis=0)\n",
    "    else:\n",
    "        del_index += 1\n",
    "\n",
    "voltage = preprocess.trace2volt(trace)\n",
    "\n",
    "points, labels = preprocess.window_split(voltage, window_size = 16, points_size = 15)\n",
    "points = torch.from_numpy(np.squeeze(points))\n",
    "labels = torch.from_numpy(np.squeeze(labels))\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(points, labels, train_size=0.1)\n",
    "\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
    "crit = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "674579a6-7881-41ee-9589-3ea97315ecd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Complete: Time -2.6662378311157227 Loss: 587.1778851406265\n",
      "Batch Complete: Time -2.8960859775543213 Loss: 585.3597129320218\n",
      "Batch Complete: Time -2.7724034786224365 Loss: 589.639864671114\n",
      "Batch Complete: Time -2.9743220806121826 Loss: 596.219682378934\n",
      "Batch Complete: Time -2.7819461822509766 Loss: 590.2347914037812\n",
      "Batch Complete: Time -3.4701781272888184 Loss: 582.4690958055418\n",
      "Batch Complete: Time -2.8219363689422607 Loss: 587.8384309591423\n",
      "Batch Complete: Time -2.6139931678771973 Loss: 593.5033284401806\n",
      "Batch Complete: Time -2.57891583442688 Loss: 585.8708737254155\n",
      "Batch Complete: Time -5.152312755584717 Loss: 585.2333247967224\n",
      "Batch Complete: Time -4.216818809509277 Loss: 590.4881075092669\n",
      "Batch Complete: Time -3.6616885662078857 Loss: 590.217066067216\n",
      "Batch Complete: Time -3.30703067779541 Loss: 585.8152324164896\n",
      "Batch Complete: Time -4.025714159011841 Loss: 590.8566488355168\n",
      "Batch Complete: Time -3.6525044441223145 Loss: 591.6664037124865\n",
      "Batch Complete: Time -3.72701096534729 Loss: 592.5829283733418\n",
      "Batch Complete: Time -3.575150966644287 Loss: 584.3944560805896\n",
      "Batch Complete: Time -3.7782821655273438 Loss: 589.9474100348717\n",
      "Batch Complete: Time -3.715369939804077 Loss: 585.9371029663682\n",
      "Batch Complete: Time -3.8984262943267822 Loss: 582.5958029529819\n",
      "Batch Complete: Time -4.366471529006958 Loss: 588.9316667730055\n",
      "Batch Complete: Time -4.159176349639893 Loss: 589.9182805139836\n",
      "Batch Complete: Time -3.8326878547668457 Loss: 579.7247247175711\n",
      "Batch Complete: Time -3.580989360809326 Loss: 591.9519097400038\n",
      "Batch Complete: Time -3.850623846054077 Loss: 591.6991754695773\n",
      "Batch Complete: Time -3.494882345199585 Loss: 579.0573623295984\n",
      "Batch Complete: Time -1.5494012832641602 Loss: 605.105412563399\n",
      "Batch Complete: Time -3.7568464279174805 Loss: 583.2631443392613\n",
      "Batch Complete: Time -3.5907974243164062 Loss: 580.4253042826889\n",
      "Batch Complete: Time -3.8785321712493896 Loss: 588.510536393338\n",
      "Batch Complete: Time -3.722468137741089 Loss: 591.3891390130857\n",
      "Batch Complete: Time -3.4857187271118164 Loss: 585.4003566095593\n",
      "Batch Complete: Time -3.781942844390869 Loss: 584.403273746418\n",
      "Batch Complete: Time -3.6036696434020996 Loss: 585.3329364478863\n",
      "Batch Complete: Time -3.5690300464630127 Loss: 579.5753637018069\n",
      "Batch Complete: Time -3.6218888759613037 Loss: 588.5341741220702\n",
      "Batch Complete: Time -3.708847999572754 Loss: 592.7238573694358\n",
      "Batch Complete: Time -3.9714906215667725 Loss: 589.9705915318069\n",
      "Batch Complete: Time -4.104835510253906 Loss: 586.0032484505817\n",
      "Batch Complete: Time -3.84694504737854 Loss: 585.78908111864\n",
      "Batch Complete: Time -3.796522855758667 Loss: 584.0174619713902\n",
      "Batch Complete: Time -3.7073142528533936 Loss: 578.1484725228431\n",
      "Batch Complete: Time -3.7797017097473145 Loss: 581.3636875477619\n",
      "Batch Complete: Time -3.7828433513641357 Loss: 589.3993781604029\n",
      "Batch Complete: Time -3.89365816116333 Loss: 589.5853454210243\n",
      "Batch Complete: Time -3.7136425971984863 Loss: 579.8066507731094\n",
      "Batch Complete: Time -3.7180581092834473 Loss: 585.3603671488798\n",
      "Batch Complete: Time -3.610743999481201 Loss: 586.981422132912\n",
      "Batch Complete: Time -3.8226265907287598 Loss: 588.5478722917474\n",
      "Batch Complete: Time -4.059616804122925 Loss: 590.4038240505014\n",
      "Batch Complete: Time -3.959723472595215 Loss: 585.4943032874061\n",
      "Batch Complete: Time -4.147715091705322 Loss: 584.1755252945023\n",
      "Batch Complete: Time -3.960637331008911 Loss: 591.4373386710922\n",
      "Batch Complete: Time -1.7953217029571533 Loss: 594.7088096063812\n",
      "Batch Complete: Time -3.860363245010376 Loss: 583.9378512946233\n",
      "Batch Complete: Time -4.330134153366089 Loss: 591.7847345084476\n",
      "Batch Complete: Time -3.9593124389648438 Loss: 584.3763456963363\n",
      "Batch Complete: Time -4.041649580001831 Loss: 585.4550903375886\n",
      "Batch Complete: Time -3.591137409210205 Loss: 590.5434582281824\n",
      "Batch Complete: Time -4.038662910461426 Loss: 588.0899692179572\n",
      "Batch Complete: Time -4.16554594039917 Loss: 587.4356669538101\n",
      "Batch Complete: Time -3.6736531257629395 Loss: 588.4433574845411\n",
      "Batch Complete: Time -3.8754448890686035 Loss: 571.9826301329431\n",
      "Batch Complete: Time -3.8112685680389404 Loss: 591.5638374727348\n",
      "Batch Complete: Time -3.905534029006958 Loss: 573.462418894835\n",
      "Batch Complete: Time -3.764517068862915 Loss: 578.3400242085587\n",
      "Batch Complete: Time -3.8048031330108643 Loss: 585.3430292948141\n",
      "Batch Complete: Time -3.780205726623535 Loss: 582.2927750534803\n",
      "Batch Complete: Time -3.9611458778381348 Loss: 582.0447687007271\n",
      "Batch Complete: Time -3.6834213733673096 Loss: 579.5262828091436\n",
      "Batch Complete: Time -3.772840738296509 Loss: 587.196776284699\n",
      "Batch Complete: Time -4.301308870315552 Loss: 585.1287717485912\n",
      "Batch Complete: Time -5.703914403915405 Loss: 579.4391531817054\n",
      "Batch Complete: Time -5.458129167556763 Loss: 574.5802748077319\n",
      "Batch Complete: Time -5.1025002002716064 Loss: 586.2627202529594\n",
      "Batch Complete: Time -4.109759569168091 Loss: 584.3192485348941\n",
      "Batch Complete: Time -4.265732288360596 Loss: 581.3506221495963\n",
      "Batch Complete: Time -3.7766242027282715 Loss: 571.7269780797792\n",
      "Batch Complete: Time -3.956810235977173 Loss: 584.808053938522\n",
      "Batch Complete: Time -4.5624754428863525 Loss: 582.0580181317562\n",
      "Batch Complete: Time -2.014911651611328 Loss: 600.4825773510855\n",
      "Batch Complete: Time -4.1962502002716064 Loss: 586.2523531508413\n",
      "Batch Complete: Time -3.625638008117676 Loss: 574.7344550437513\n",
      "Batch Complete: Time -3.4700801372528076 Loss: 577.2754057573213\n",
      "Batch Complete: Time -3.401904582977295 Loss: 577.9531688439976\n",
      "Batch Complete: Time -3.329045057296753 Loss: 577.9834126172937\n",
      "Batch Complete: Time -3.9274039268493652 Loss: 574.6896652687353\n",
      "Batch Complete: Time -4.66486930847168 Loss: 586.385533630915\n",
      "Batch Complete: Time -4.031188011169434 Loss: 577.2651814193737\n",
      "Batch Complete: Time -3.936837911605835 Loss: 586.853677688809\n",
      "Batch Complete: Time -3.7869715690612793 Loss: 587.200460831798\n",
      "Batch Complete: Time -3.9119558334350586 Loss: 581.463506935326\n",
      "Batch Complete: Time -5.451223134994507 Loss: 578.5893195867934\n",
      "Batch Complete: Time -3.809692144393921 Loss: 571.303595556367\n",
      "Batch Complete: Time -3.985776662826538 Loss: 581.8197171403202\n",
      "Batch Complete: Time -3.66056489944458 Loss: 579.0559937568174\n",
      "Batch Complete: Time -3.556288957595825 Loss: 579.6045223307747\n",
      "Batch Complete: Time -3.869931697845459 Loss: 576.221451749509\n",
      "Batch Complete: Time -3.9438388347625732 Loss: 579.1545957351644\n",
      "Batch Complete: Time -3.870129108428955 Loss: 584.1138171270633\n",
      "Batch Complete: Time -3.8368823528289795 Loss: 578.8171552283633\n",
      "Batch Complete: Time -3.7528154850006104 Loss: 575.3483073040327\n",
      "Batch Complete: Time -3.9430577754974365 Loss: 579.9964544207866\n",
      "Batch Complete: Time -4.0493481159210205 Loss: 574.859920151981\n",
      "Batch Complete: Time -4.225261211395264 Loss: 583.5571950661403\n",
      "Batch Complete: Time -4.644330263137817 Loss: 576.1023584837404\n",
      "Batch Complete: Time -3.138394355773926 Loss: 579.4417496018993\n",
      "Batch Complete: Time -1.2218894958496094 Loss: 594.2268988061701\n",
      "Batch Complete: Time -2.7629318237304688 Loss: 568.6713441857268\n",
      "Batch Complete: Time -2.825754404067993 Loss: 583.8338344167622\n",
      "Batch Complete: Time -4.742227077484131 Loss: 577.7824572086525\n",
      "Batch Complete: Time -3.934177875518799 Loss: 577.5607659279019\n",
      "Batch Complete: Time -3.180692434310913 Loss: 578.0439237284005\n",
      "Batch Complete: Time -4.022050380706787 Loss: 564.9158674717605\n",
      "Batch Complete: Time -4.356038808822632 Loss: 573.9463025074043\n",
      "Batch Complete: Time -4.08772611618042 Loss: 579.613856242243\n",
      "Batch Complete: Time -3.4945061206817627 Loss: 573.3520847258964\n",
      "Batch Complete: Time -3.8702762126922607 Loss: 571.8711403166135\n",
      "Batch Complete: Time -4.4006922245025635 Loss: 578.7314827047652\n",
      "Batch Complete: Time -4.064213991165161 Loss: 572.5239439213849\n",
      "Batch Complete: Time -3.9736649990081787 Loss: 571.3951061503885\n",
      "Batch Complete: Time -4.034843683242798 Loss: 577.9802582830271\n",
      "Batch Complete: Time -3.876168966293335 Loss: 570.6751984118002\n",
      "Batch Complete: Time -3.986128807067871 Loss: 573.63495015771\n",
      "Batch Complete: Time -3.994333267211914 Loss: 576.843191339903\n",
      "Batch Complete: Time -3.888864755630493 Loss: 571.4250427093862\n",
      "Batch Complete: Time -2.7432024478912354 Loss: 577.00328029899\n",
      "Batch Complete: Time -3.2971198558807373 Loss: 577.8872919559465\n",
      "Batch Complete: Time -4.756550312042236 Loss: 569.4733343411098\n",
      "Batch Complete: Time -3.8182241916656494 Loss: 572.0616324686453\n",
      "Batch Complete: Time -4.350552797317505 Loss: 570.6873586930164\n",
      "Batch Complete: Time -3.9751577377319336 Loss: 570.6810928432569\n",
      "Batch Complete: Time -3.8356106281280518 Loss: 563.4716700902552\n",
      "Batch Complete: Time -4.0185370445251465 Loss: 574.1483099210367\n",
      "Batch Complete: Time -1.6712231636047363 Loss: 591.4726691440953\n",
      "Batch Complete: Time -4.0257227420806885 Loss: 570.3961418960055\n",
      "Batch Complete: Time -4.2737555503845215 Loss: 564.9367783212482\n",
      "Batch Complete: Time -3.7904036045074463 Loss: 574.5049167017837\n",
      "Batch Complete: Time -3.862886667251587 Loss: 567.9550564114281\n",
      "Batch Complete: Time -3.8477249145507812 Loss: 568.0033859014477\n",
      "Batch Complete: Time -4.11445689201355 Loss: 570.3177505988518\n",
      "Batch Complete: Time -3.7097558975219727 Loss: 567.156565727094\n",
      "Batch Complete: Time -3.689544916152954 Loss: 563.6042170298838\n",
      "Batch Complete: Time -3.9559080600738525 Loss: 563.6588483236304\n",
      "Batch Complete: Time -4.146953344345093 Loss: 563.7250156820293\n",
      "Batch Complete: Time -3.7262275218963623 Loss: 564.50485353194\n",
      "Batch Complete: Time -3.8346104621887207 Loss: 566.3530296763629\n",
      "Batch Complete: Time -3.7446768283843994 Loss: 566.1604044304623\n",
      "Batch Complete: Time -3.765584945678711 Loss: 558.4777271055559\n",
      "Batch Complete: Time -3.8911292552948 Loss: 563.2296469304653\n",
      "Batch Complete: Time -3.826805830001831 Loss: 557.1130981643321\n",
      "Batch Complete: Time -4.070840120315552 Loss: 555.6679610686085\n",
      "Batch Complete: Time -4.019703149795532 Loss: 567.7724003994063\n",
      "Batch Complete: Time -3.9226667881011963 Loss: 559.5318132037785\n",
      "Batch Complete: Time -3.824335813522339 Loss: 556.9984880962766\n",
      "Batch Complete: Time -3.834110975265503 Loss: 557.1426527630309\n",
      "Batch Complete: Time -3.867816209793091 Loss: 559.3521823016948\n",
      "Batch Complete: Time -3.738513708114624 Loss: 550.6678367401502\n",
      "Batch Complete: Time -3.9005911350250244 Loss: 561.0749408308783\n",
      "Batch Complete: Time -4.097660779953003 Loss: 557.4869320949723\n",
      "Batch Complete: Time -3.857238292694092 Loss: 555.4924809359425\n",
      "Batch Complete: Time -1.7853541374206543 Loss: 580.7581290805731\n",
      "Batch Complete: Time -3.8825736045837402 Loss: 549.6716911336733\n",
      "Batch Complete: Time -4.1522581577301025 Loss: 549.9343925400831\n",
      "Batch Complete: Time -3.974377155303955 Loss: 547.2000259034078\n",
      "Batch Complete: Time -3.7625272274017334 Loss: 552.6276012205412\n",
      "Batch Complete: Time -3.917938232421875 Loss: 545.4215034258103\n",
      "Batch Complete: Time -3.862720251083374 Loss: 548.9733721864715\n",
      "Batch Complete: Time -3.5751028060913086 Loss: 546.1488610473423\n",
      "Batch Complete: Time -4.184540033340454 Loss: 545.8978006344182\n",
      "Batch Complete: Time -4.2404608726501465 Loss: 536.0110123403413\n",
      "Batch Complete: Time -3.8014748096466064 Loss: 543.9288452493281\n",
      "Batch Complete: Time -3.9419732093811035 Loss: 551.0623163740864\n",
      "Batch Complete: Time -3.918964385986328 Loss: 547.3330417112202\n",
      "Batch Complete: Time -4.145888566970825 Loss: 547.1462610570586\n",
      "Batch Complete: Time -2.6351728439331055 Loss: 554.239969615677\n",
      "Batch Complete: Time -2.8119122982025146 Loss: 546.5255130142588\n",
      "Batch Complete: Time -2.7008137702941895 Loss: 551.6093349053504\n",
      "Batch Complete: Time -2.60562801361084 Loss: 540.2734493457076\n",
      "Batch Complete: Time -2.6031153202056885 Loss: 546.6327477231381\n",
      "Batch Complete: Time -2.619985818862915 Loss: 535.1522009174867\n",
      "Batch Complete: Time -2.5623369216918945 Loss: 539.3612268608078\n",
      "Batch Complete: Time -3.3979151248931885 Loss: 550.2368996461463\n",
      "Batch Complete: Time -3.903238534927368 Loss: 545.4549255947161\n",
      "Batch Complete: Time -3.1337730884552 Loss: 539.9240167718258\n",
      "Batch Complete: Time -3.6144421100616455 Loss: 544.9015771014846\n",
      "Batch Complete: Time -2.7277393341064453 Loss: 540.5814415922104\n",
      "Batch Complete: Time -3.060953140258789 Loss: 542.3807328844536\n",
      "Batch Complete: Time -1.4967138767242432 Loss: 555.1277801388572\n",
      "Batch Complete: Time -3.3977272510528564 Loss: 541.3947726516292\n",
      "Batch Complete: Time -3.242321014404297 Loss: 534.1517774017225\n",
      "Batch Complete: Time -3.3190252780914307 Loss: 540.4147607973223\n",
      "Batch Complete: Time -4.4715962409973145 Loss: 545.733899130054\n",
      "Batch Complete: Time -4.079630374908447 Loss: 543.862894587382\n",
      "Batch Complete: Time -4.14581036567688 Loss: 541.6737932602517\n",
      "Batch Complete: Time -4.889923334121704 Loss: 536.7433582463527\n",
      "Batch Complete: Time -3.9892568588256836 Loss: 547.5953925416572\n",
      "Batch Complete: Time -3.5802135467529297 Loss: 539.5647665035436\n",
      "Batch Complete: Time -3.9503304958343506 Loss: 534.2219792489451\n",
      "Batch Complete: Time -3.83768630027771 Loss: 551.0954540478369\n",
      "Batch Complete: Time -3.582005739212036 Loss: 541.7795272561741\n",
      "Batch Complete: Time -3.8976001739501953 Loss: 535.6238569482181\n",
      "Batch Complete: Time -4.030704975128174 Loss: 540.379960042119\n",
      "Batch Complete: Time -4.01846170425415 Loss: 532.7636460458474\n",
      "Batch Complete: Time -3.0469651222229004 Loss: 540.3196059813118\n",
      "Batch Complete: Time -2.5584890842437744 Loss: 542.0323689038025\n",
      "Batch Complete: Time -3.75634765625 Loss: 542.0462755488121\n",
      "Batch Complete: Time -3.3283045291900635 Loss: 539.2837254352283\n",
      "Batch Complete: Time -3.424452543258667 Loss: 539.0512599706941\n",
      "Batch Complete: Time -3.3646950721740723 Loss: 531.2893529390614\n",
      "Batch Complete: Time -3.5500762462615967 Loss: 531.3539517252326\n",
      "Batch Complete: Time -4.938227653503418 Loss: 524.9987371632562\n",
      "Batch Complete: Time -4.15365195274353 Loss: 537.576189541285\n",
      "Batch Complete: Time -3.1330149173736572 Loss: 535.3737063734999\n",
      "Batch Complete: Time -3.015474557876587 Loss: 537.5325429224008\n",
      "Batch Complete: Time -1.3858656883239746 Loss: 591.4612898201531\n",
      "Batch Complete: Time -5.410520792007446 Loss: 537.88497827387\n",
      "Batch Complete: Time -3.0070905685424805 Loss: 539.0405546139905\n",
      "Batch Complete: Time -3.073223114013672 Loss: 536.6523147999085\n",
      "Batch Complete: Time -2.606215000152588 Loss: 536.5515438287299\n",
      "Batch Complete: Time -2.7421875 Loss: 539.3031124770764\n",
      "Batch Complete: Time -2.7671031951904297 Loss: 535.8792652339115\n",
      "Batch Complete: Time -4.437070608139038 Loss: 535.4252601308365\n",
      "Batch Complete: Time -3.1822688579559326 Loss: 539.6479051262874\n",
      "Batch Complete: Time -2.98649001121521 Loss: 530.8288845526778\n",
      "Batch Complete: Time -2.8691513538360596 Loss: 539.5973298544577\n",
      "Batch Complete: Time -3.1609318256378174 Loss: 536.6673842407909\n",
      "Batch Complete: Time -3.370079517364502 Loss: 540.2594296861549\n",
      "Batch Complete: Time -2.8946378231048584 Loss: 542.8042335117773\n",
      "Batch Complete: Time -2.8532824516296387 Loss: 538.0564333937311\n",
      "Batch Complete: Time -2.8413279056549072 Loss: 537.7098688065299\n",
      "Batch Complete: Time -2.800121307373047 Loss: 528.284633319748\n",
      "Batch Complete: Time -2.8369500637054443 Loss: 537.4363742319831\n",
      "Batch Complete: Time -2.8415205478668213 Loss: 537.7998697865725\n",
      "Batch Complete: Time -2.7946298122406006 Loss: 530.7689779943985\n",
      "Batch Complete: Time -2.834200859069824 Loss: 534.0474229861923\n",
      "Batch Complete: Time -2.801743507385254 Loss: 530.3025768016983\n",
      "Batch Complete: Time -2.842888593673706 Loss: 527.3324030491887\n",
      "Batch Complete: Time -2.8059659004211426 Loss: 535.4986783682851\n",
      "Batch Complete: Time -2.8439388275146484 Loss: 534.3175283847464\n",
      "Batch Complete: Time -2.8329074382781982 Loss: 541.1776381468609\n",
      "Batch Complete: Time -2.8739373683929443 Loss: 527.7690349933401\n",
      "Batch Complete: Time -1.2393152713775635 Loss: 555.5637355665579\n",
      "Batch Complete: Time -2.8807408809661865 Loss: 533.28875723882\n",
      "Batch Complete: Time -2.9577717781066895 Loss: 530.7510955773989\n",
      "Batch Complete: Time -2.804060220718384 Loss: 534.3971165732614\n",
      "Batch Complete: Time -2.839172124862671 Loss: 532.1544049902183\n",
      "Batch Complete: Time -2.8130717277526855 Loss: 535.7395344144012\n",
      "Batch Complete: Time -2.8693881034851074 Loss: 535.431931303636\n",
      "Batch Complete: Time -2.764584541320801 Loss: 537.0601717025158\n",
      "Batch Complete: Time -2.8485846519470215 Loss: 534.631240907806\n",
      "Batch Complete: Time -2.8611605167388916 Loss: 535.0790895324216\n",
      "Batch Complete: Time -2.828842878341675 Loss: 526.6333704728139\n",
      "Batch Complete: Time -2.8800008296966553 Loss: 528.2654676987712\n",
      "Batch Complete: Time -2.8799095153808594 Loss: 530.8326343256118\n",
      "Batch Complete: Time -2.8303685188293457 Loss: 532.579913831458\n",
      "Batch Complete: Time -2.7898454666137695 Loss: 532.1119870126678\n",
      "Batch Complete: Time -2.8351728916168213 Loss: 524.5743906243986\n",
      "Batch Complete: Time -2.8588342666625977 Loss: 525.3928671151218\n",
      "Batch Complete: Time -2.8413679599761963 Loss: 527.9833469014185\n",
      "Batch Complete: Time -2.7575323581695557 Loss: 528.7475929629911\n",
      "Batch Complete: Time -2.8929920196533203 Loss: 529.9190339635185\n",
      "Batch Complete: Time -2.75948166847229 Loss: 529.7989013261466\n",
      "Batch Complete: Time -2.8085689544677734 Loss: 526.6513154656116\n",
      "Batch Complete: Time -2.7794601917266846 Loss: 523.4338618608058\n",
      "Batch Complete: Time -2.9242613315582275 Loss: 529.0499013914941\n",
      "Batch Complete: Time -2.805006265640259 Loss: 529.1576455800798\n",
      "Batch Complete: Time -2.852555990219116 Loss: 528.7865940876309\n",
      "Batch Complete: Time -2.9546637535095215 Loss: 529.7419985119228\n",
      "Batch Complete: Time -1.2322824001312256 Loss: 586.8888134274381\n",
      "Batch Complete: Time -2.865105628967285 Loss: 521.7486768971273\n",
      "Batch Complete: Time -2.9531121253967285 Loss: 529.4131930771481\n",
      "Batch Complete: Time -2.8996825218200684 Loss: 533.7689212152985\n",
      "Batch Complete: Time -2.9082372188568115 Loss: 536.6672370533036\n",
      "Batch Complete: Time -2.7876439094543457 Loss: 530.5221128592402\n",
      "Batch Complete: Time -2.8523266315460205 Loss: 521.7898763662382\n",
      "Batch Complete: Time -2.89530086517334 Loss: 526.0162085980896\n",
      "Batch Complete: Time -2.8238778114318848 Loss: 529.5848946906364\n",
      "Batch Complete: Time -2.913910388946533 Loss: 533.3449407934962\n",
      "Batch Complete: Time -2.832669734954834 Loss: 522.847150052963\n",
      "Batch Complete: Time -2.875697612762451 Loss: 525.8348535509886\n",
      "Batch Complete: Time -2.81416654586792 Loss: 524.3863597218748\n",
      "Batch Complete: Time -2.847926378250122 Loss: 519.6633838973071\n",
      "Batch Complete: Time -2.976257085800171 Loss: 532.8826302366942\n",
      "Batch Complete: Time -2.8275740146636963 Loss: 525.0396797563269\n",
      "Batch Complete: Time -2.822397470474243 Loss: 521.7203853388406\n",
      "Batch Complete: Time -2.9099998474121094 Loss: 523.8846185357345\n",
      "Batch Complete: Time -2.8249828815460205 Loss: 524.4731871071758\n",
      "Batch Complete: Time -2.8507497310638428 Loss: 528.4741760080725\n",
      "Batch Complete: Time -2.9118576049804688 Loss: 521.1890093262685\n",
      "Batch Complete: Time -2.8436622619628906 Loss: 526.6496864011407\n",
      "Batch Complete: Time -2.8874688148498535 Loss: 521.656579593666\n",
      "Batch Complete: Time -2.8537509441375732 Loss: 525.9180721855314\n",
      "Batch Complete: Time -2.9079105854034424 Loss: 517.8112994898495\n",
      "Batch Complete: Time -2.8125452995300293 Loss: 524.9134538796505\n",
      "Batch Complete: Time -2.9113426208496094 Loss: 526.5140303249667\n",
      "Batch Complete: Time -1.2875034809112549 Loss: 573.6366882778467\n",
      "Batch Complete: Time -2.9411237239837646 Loss: 522.4475713138941\n",
      "Batch Complete: Time -2.8826873302459717 Loss: 523.7125622078588\n",
      "Batch Complete: Time -2.869973659515381 Loss: 523.64021846489\n",
      "Batch Complete: Time -2.834895610809326 Loss: 516.5090891824341\n",
      "Batch Complete: Time -2.8312816619873047 Loss: 525.4835331571068\n",
      "Batch Complete: Time -2.824164390563965 Loss: 525.8401932357306\n",
      "Batch Complete: Time -2.822638988494873 Loss: 521.0168471652357\n",
      "Batch Complete: Time -2.93517804145813 Loss: 522.5552008910289\n",
      "Batch Complete: Time -2.885401964187622 Loss: 522.2599137323504\n",
      "Batch Complete: Time -2.8244333267211914 Loss: 521.8419456862098\n",
      "Batch Complete: Time -2.8468339443206787 Loss: 523.4762053865521\n",
      "Batch Complete: Time -2.9376072883605957 Loss: 521.0498920141913\n",
      "Batch Complete: Time -2.895040512084961 Loss: 520.5137023601051\n",
      "Batch Complete: Time -2.780118703842163 Loss: 524.4653849050493\n",
      "Batch Complete: Time -2.915648937225342 Loss: 525.1899425139242\n",
      "Batch Complete: Time -2.8001787662506104 Loss: 520.8694702249821\n",
      "Batch Complete: Time -2.852552890777588 Loss: 509.8652046136334\n",
      "Batch Complete: Time -2.804534912109375 Loss: 520.1482757167666\n",
      "Batch Complete: Time -2.864323377609253 Loss: 516.912971320155\n",
      "Batch Complete: Time -2.781219720840454 Loss: 519.0615014172654\n",
      "Batch Complete: Time -2.85785174369812 Loss: 515.8259047165741\n",
      "Batch Complete: Time -2.8418006896972656 Loss: 519.9005565645945\n",
      "Batch Complete: Time -2.878784418106079 Loss: 519.1589179049323\n",
      "Batch Complete: Time -2.780970335006714 Loss: 514.6176696973445\n",
      "Batch Complete: Time -2.828721284866333 Loss: 510.5575269519267\n",
      "Batch Complete: Time -2.8282437324523926 Loss: 503.80367936516063\n",
      "Batch Complete: Time -1.2708518505096436 Loss: 558.7270021990685\n",
      "Batch Complete: Time -2.918551206588745 Loss: 511.5732947968975\n",
      "Batch Complete: Time -2.898920774459839 Loss: 512.6858746453835\n",
      "Batch Complete: Time -2.9015915393829346 Loss: 511.53662360041847\n",
      "Batch Complete: Time -2.8813846111297607 Loss: 509.4018295223989\n",
      "Batch Complete: Time -2.789151906967163 Loss: 517.3207218173493\n",
      "Batch Complete: Time -2.955714225769043 Loss: 512.7647211336025\n",
      "Batch Complete: Time -2.7768547534942627 Loss: 509.66514481976117\n",
      "Batch Complete: Time -2.88206148147583 Loss: 506.40773807013164\n",
      "Batch Complete: Time -2.830134391784668 Loss: 512.8377436919909\n",
      "Batch Complete: Time -2.910872220993042 Loss: 511.59251363206926\n",
      "Batch Complete: Time -3.5185091495513916 Loss: 504.57036289125796\n",
      "Batch Complete: Time -3.4351999759674072 Loss: 508.77518386089446\n",
      "Batch Complete: Time -2.814143657684326 Loss: 509.65544114745325\n",
      "Batch Complete: Time -2.7810091972351074 Loss: 506.49882672858547\n",
      "Batch Complete: Time -2.8056859970092773 Loss: 506.8147408722906\n",
      "Batch Complete: Time -2.809518814086914 Loss: 508.29240629824466\n",
      "Batch Complete: Time -2.811793327331543 Loss: 500.45577239890207\n",
      "Batch Complete: Time -2.7999138832092285 Loss: 495.5574639364332\n",
      "Batch Complete: Time -2.7664310932159424 Loss: 497.3135085307191\n",
      "Batch Complete: Time -2.8673315048217773 Loss: 505.1518526258356\n",
      "Batch Complete: Time -2.82568621635437 Loss: 503.22957454976284\n",
      "Batch Complete: Time -2.8372137546539307 Loss: 489.58729263764076\n",
      "Batch Complete: Time -2.7551991939544678 Loss: 499.895564442397\n",
      "Batch Complete: Time -2.819925546646118 Loss: 498.11022618203384\n",
      "Batch Complete: Time -2.7354679107666016 Loss: 496.31522275060576\n",
      "Batch Complete: Time -2.801222085952759 Loss: 499.1291493946489\n",
      "Batch Complete: Time -1.2564833164215088 Loss: 547.3932565309635\n",
      "Batch Complete: Time -3.1113812923431396 Loss: 494.5267781764496\n",
      "Batch Complete: Time -2.819174289703369 Loss: 482.43215653354804\n",
      "Batch Complete: Time -2.844364643096924 Loss: 495.800115446933\n",
      "Batch Complete: Time -2.8384037017822266 Loss: 483.40818596337976\n",
      "Batch Complete: Time -2.8046369552612305 Loss: 485.64189054133317\n",
      "Batch Complete: Time -2.748568534851074 Loss: 487.7150380221058\n",
      "Batch Complete: Time -2.773797035217285 Loss: 480.3510280140363\n",
      "Batch Complete: Time -2.7346456050872803 Loss: 484.75176371062497\n",
      "Batch Complete: Time -2.8545236587524414 Loss: 485.4762735313989\n",
      "Batch Complete: Time -2.787256956100464 Loss: 478.49712960462017\n",
      "Batch Complete: Time -2.838015556335449 Loss: 476.9558687161371\n",
      "Batch Complete: Time -2.782644271850586 Loss: 476.9013980735872\n",
      "Batch Complete: Time -2.8253166675567627 Loss: 473.09678772589245\n",
      "Batch Complete: Time -2.7930164337158203 Loss: 477.275696847084\n",
      "Batch Complete: Time -2.9262986183166504 Loss: 465.28260837254544\n",
      "Batch Complete: Time -2.787224292755127 Loss: 471.1577238518386\n",
      "Batch Complete: Time -2.825378894805908 Loss: 475.28815656190244\n",
      "Batch Complete: Time -2.792442560195923 Loss: 472.37020276234426\n",
      "Batch Complete: Time -2.838017225265503 Loss: 464.49092852451844\n",
      "Batch Complete: Time -2.7433629035949707 Loss: 463.0679308589176\n",
      "Batch Complete: Time -2.8160901069641113 Loss: 463.2909623730576\n",
      "Batch Complete: Time -2.7823033332824707 Loss: 459.5749100421443\n",
      "Batch Complete: Time -2.8124802112579346 Loss: 464.9751229632787\n",
      "Batch Complete: Time -2.7782111167907715 Loss: 465.7416687206355\n",
      "Batch Complete: Time -3.0665085315704346 Loss: 459.35211170677684\n",
      "Batch Complete: Time -2.8383541107177734 Loss: 462.6952150771791\n",
      "Batch Complete: Time -1.2908618450164795 Loss: 511.46692981942226\n",
      "Batch Complete: Time -2.912135124206543 Loss: 452.78481601025845\n",
      "Batch Complete: Time -2.839725971221924 Loss: 460.64150815655944\n",
      "Batch Complete: Time -2.8674113750457764 Loss: 459.8191859776383\n",
      "Batch Complete: Time -2.8656234741210938 Loss: 461.83377586789743\n",
      "Batch Complete: Time -2.76249361038208 Loss: 459.01542805760187\n",
      "Batch Complete: Time -2.8654024600982666 Loss: 459.3178169879379\n",
      "Batch Complete: Time -2.7688748836517334 Loss: 457.92437604970354\n",
      "Batch Complete: Time -2.831153392791748 Loss: 454.6943998859433\n",
      "Batch Complete: Time -2.778205394744873 Loss: 459.07735656557713\n",
      "Batch Complete: Time -2.9296441078186035 Loss: 456.93961142917686\n",
      "Batch Complete: Time -2.7686355113983154 Loss: 464.3448634523806\n",
      "Batch Complete: Time -2.8198134899139404 Loss: 460.39041134244184\n",
      "Batch Complete: Time -2.8743813037872314 Loss: 456.86321823140435\n",
      "Batch Complete: Time -2.8476903438568115 Loss: 448.4946771687189\n",
      "Batch Complete: Time -2.773028612136841 Loss: 455.7956638764256\n",
      "Batch Complete: Time -2.886091947555542 Loss: 457.2124141538344\n",
      "Batch Complete: Time -2.911386728286743 Loss: 451.9331366248174\n",
      "Batch Complete: Time -2.8589541912078857 Loss: 458.94751331864524\n",
      "Batch Complete: Time -2.8118064403533936 Loss: 451.9593186301298\n",
      "Batch Complete: Time -3.001286506652832 Loss: 458.1924036145472\n",
      "Batch Complete: Time -2.8201448917388916 Loss: 453.33690048451285\n",
      "Batch Complete: Time -2.8356964588165283 Loss: 457.18996799825084\n",
      "Batch Complete: Time -2.783599615097046 Loss: 455.86190740640416\n",
      "Batch Complete: Time -2.9177896976470947 Loss: 449.0507941041768\n",
      "Batch Complete: Time -2.7865982055664062 Loss: 460.1757330801307\n",
      "Batch Complete: Time -2.8424317836761475 Loss: 458.6027814217212\n",
      "Batch Complete: Time -1.2535467147827148 Loss: 501.89316584056957\n",
      "Batch Complete: Time -2.996002197265625 Loss: 450.3465492114696\n",
      "Batch Complete: Time -2.845472812652588 Loss: 451.0591539059383\n",
      "Batch Complete: Time -2.891967296600342 Loss: 457.04106457835974\n",
      "Batch Complete: Time -2.867140293121338 Loss: 451.0130906050176\n",
      "Batch Complete: Time -2.830508232116699 Loss: 455.5042704735349\n",
      "Batch Complete: Time -2.7946252822875977 Loss: 457.4251265767704\n",
      "Batch Complete: Time -2.8181967735290527 Loss: 461.9126391790236\n",
      "Batch Complete: Time -2.846604824066162 Loss: 454.75481113710464\n",
      "Batch Complete: Time -2.872868537902832 Loss: 455.2460714153609\n",
      "Batch Complete: Time -2.8488426208496094 Loss: 454.04127141396583\n",
      "Batch Complete: Time -2.943979501724243 Loss: 455.96726127831766\n",
      "Batch Complete: Time -2.8058929443359375 Loss: 451.95539498945925\n",
      "Batch Complete: Time -2.894451141357422 Loss: 455.51574144829715\n",
      "Batch Complete: Time -2.806413173675537 Loss: 453.60157315390876\n",
      "Batch Complete: Time -2.8663394451141357 Loss: 448.45267639755406\n",
      "Batch Complete: Time -2.8090264797210693 Loss: 450.1300127403336\n",
      "Batch Complete: Time -2.8598885536193848 Loss: 450.49877416579466\n",
      "Batch Complete: Time -2.9375545978546143 Loss: 457.03237194819036\n",
      "Batch Complete: Time -2.8721656799316406 Loss: 453.62716655010223\n",
      "Batch Complete: Time -2.8288729190826416 Loss: 455.04437920198967\n",
      "Batch Complete: Time -2.853240728378296 Loss: 458.2021458088554\n",
      "Batch Complete: Time -2.8575780391693115 Loss: 452.17741254418416\n",
      "Batch Complete: Time -2.8675832748413086 Loss: 458.9497927864873\n",
      "Batch Complete: Time -2.8051767349243164 Loss: 454.0818730608612\n",
      "Batch Complete: Time -2.8932247161865234 Loss: 455.5703752954743\n",
      "Batch Complete: Time -2.7929329872131348 Loss: 455.4325292448424\n",
      "Batch Complete: Time -1.27286696434021 Loss: 492.4028609934533\n",
      "Batch Complete: Time -2.905383348464966 Loss: 452.7611814521179\n",
      "Batch Complete: Time -2.9676780700683594 Loss: 453.29947368491753\n",
      "Batch Complete: Time -2.869004964828491 Loss: 458.8520974446663\n",
      "Batch Complete: Time -3.0230844020843506 Loss: 451.0519541984497\n",
      "Batch Complete: Time -2.783083915710449 Loss: 447.7831659974692\n",
      "Batch Complete: Time -2.928636312484741 Loss: 456.6930010636789\n",
      "Batch Complete: Time -2.7928731441497803 Loss: 462.90855030053484\n",
      "Batch Complete: Time -2.8903679847717285 Loss: 448.69993962956937\n",
      "Batch Complete: Time -2.884110450744629 Loss: 446.4979947804867\n",
      "Batch Complete: Time -2.9050774574279785 Loss: 453.71899487626496\n",
      "Batch Complete: Time -2.8135204315185547 Loss: 453.6858305099411\n",
      "Batch Complete: Time -2.9039063453674316 Loss: 452.0788482637554\n",
      "Batch Complete: Time -2.911461114883423 Loss: 452.1155068527505\n",
      "Batch Complete: Time -2.9065020084381104 Loss: 458.8255774858423\n",
      "Batch Complete: Time -2.804220199584961 Loss: 458.10830365947857\n",
      "Batch Complete: Time -2.866867780685425 Loss: 446.92576603779486\n",
      "Batch Complete: Time -2.787923574447632 Loss: 446.1542550002783\n",
      "Batch Complete: Time -2.8005943298339844 Loss: 453.8431902253097\n",
      "Batch Complete: Time -2.755237340927124 Loss: 451.70239607682237\n",
      "Batch Complete: Time -2.905783176422119 Loss: 449.87430504842246\n",
      "Batch Complete: Time -2.86611270904541 Loss: 450.3034808464846\n",
      "Batch Complete: Time -2.8020336627960205 Loss: 444.28904922817486\n",
      "Batch Complete: Time -2.898874282836914 Loss: 457.3453399504015\n",
      "Batch Complete: Time -2.806178331375122 Loss: 452.1935742400789\n",
      "Batch Complete: Time -2.8834540843963623 Loss: 449.64039767782316\n",
      "Batch Complete: Time -2.808143377304077 Loss: 444.066053587736\n",
      "Batch Complete: Time -1.3035492897033691 Loss: 495.8081934947903\n",
      "Batch Complete: Time -2.9318535327911377 Loss: 454.6445503516438\n",
      "Batch Complete: Time -2.8345534801483154 Loss: 451.1293088909125\n",
      "Batch Complete: Time -2.903022527694702 Loss: 455.36380755934044\n",
      "Batch Complete: Time -2.922438621520996 Loss: 457.4530032772072\n",
      "Batch Complete: Time -2.856785297393799 Loss: 452.586145582173\n",
      "Batch Complete: Time -2.8309128284454346 Loss: 453.1270277387391\n",
      "Batch Complete: Time -2.8771779537200928 Loss: 445.55269905924285\n",
      "Batch Complete: Time -2.843846321105957 Loss: 457.1629394030162\n",
      "Batch Complete: Time -2.7995786666870117 Loss: 450.5397360669689\n",
      "Batch Complete: Time -2.86852765083313 Loss: 451.88398845874707\n",
      "Batch Complete: Time -2.875983715057373 Loss: 443.97651899560174\n",
      "Batch Complete: Time -2.8936331272125244 Loss: 451.4220794296529\n",
      "Batch Complete: Time -2.7724215984344482 Loss: 447.8332750879836\n",
      "Batch Complete: Time -2.9125821590423584 Loss: 448.4704926920102\n",
      "Batch Complete: Time -2.7263784408569336 Loss: 455.70805373010336\n",
      "Batch Complete: Time -2.825953960418701 Loss: 445.0060253130566\n",
      "Batch Complete: Time -2.799210786819458 Loss: 448.17772027656036\n",
      "Batch Complete: Time -2.8950281143188477 Loss: 443.0969401345818\n",
      "Batch Complete: Time -2.7765634059906006 Loss: 444.6521996160448\n",
      "Batch Complete: Time -2.813464403152466 Loss: 447.71328690500656\n",
      "Batch Complete: Time -2.858638048171997 Loss: 446.5777351231145\n",
      "Batch Complete: Time -2.8380470275878906 Loss: 446.67196005760326\n",
      "Batch Complete: Time -2.7863271236419678 Loss: 442.63374692731344\n",
      "Batch Complete: Time -2.8155949115753174 Loss: 451.4722778279486\n",
      "Batch Complete: Time -2.8979990482330322 Loss: 442.0865029765857\n",
      "Batch Complete: Time -2.8508384227752686 Loss: 443.444076985113\n",
      "Batch Complete: Time -1.2363126277923584 Loss: 488.6464037373061\n",
      "Batch Complete: Time -2.9289016723632812 Loss: 440.89154997257054\n",
      "Batch Complete: Time -2.855863332748413 Loss: 444.26012788279877\n",
      "Batch Complete: Time -2.8886477947235107 Loss: 438.825466181819\n",
      "Batch Complete: Time -2.8121697902679443 Loss: 445.6232006333936\n",
      "Batch Complete: Time -2.9467132091522217 Loss: 442.17854913602537\n",
      "Batch Complete: Time -2.860241651535034 Loss: 443.6609767468625\n",
      "Batch Complete: Time -2.760478973388672 Loss: 448.02196203374973\n",
      "Batch Complete: Time -2.837047576904297 Loss: 447.28452726534186\n",
      "Batch Complete: Time -2.840320348739624 Loss: 445.6845570366988\n",
      "Batch Complete: Time -2.876978635787964 Loss: 446.56472203715134\n",
      "Batch Complete: Time -2.779820442199707 Loss: 448.7157984592565\n",
      "Batch Complete: Time -2.922412157058716 Loss: 446.99132077544624\n",
      "Batch Complete: Time -2.766587495803833 Loss: 448.7881730927115\n",
      "Batch Complete: Time -2.8333709239959717 Loss: 454.0651892975837\n",
      "Batch Complete: Time -2.7575087547302246 Loss: 452.01256406066074\n",
      "Batch Complete: Time -2.8984858989715576 Loss: 438.8568165596498\n",
      "Batch Complete: Time -2.745347499847412 Loss: 446.2670138853713\n",
      "Batch Complete: Time -2.8247792720794678 Loss: 447.0319604907014\n",
      "Batch Complete: Time -2.790660858154297 Loss: 444.00457955455227\n",
      "Batch Complete: Time -2.8866076469421387 Loss: 448.82614830804\n",
      "Batch Complete: Time -2.79345440864563 Loss: 442.5957441805315\n",
      "Batch Complete: Time -2.8310482501983643 Loss: 437.11122300067865\n",
      "Batch Complete: Time -2.8302724361419678 Loss: 447.93807416589084\n",
      "Batch Complete: Time -2.828813076019287 Loss: 443.91744608374916\n",
      "Batch Complete: Time -2.7718582153320312 Loss: 435.2954678883279\n",
      "Batch Complete: Time -2.8517606258392334 Loss: 437.0505423220061\n",
      "Batch Complete: Time -1.2988243103027344 Loss: 492.3992772756777\n",
      "Batch Complete: Time -2.8672983646392822 Loss: 445.0971452278339\n",
      "Batch Complete: Time -2.8790719509124756 Loss: 442.8532033961135\n",
      "Batch Complete: Time -2.8160619735717773 Loss: 441.58401396676624\n",
      "Batch Complete: Time -3.0123579502105713 Loss: 441.3764786478665\n",
      "Batch Complete: Time -2.807461738586426 Loss: 441.08720567297667\n",
      "Batch Complete: Time -2.7690863609313965 Loss: 443.514364256094\n",
      "Batch Complete: Time -3.133080244064331 Loss: 437.922683747346\n",
      "Batch Complete: Time -2.7517197132110596 Loss: 444.5343372381855\n",
      "Batch Complete: Time -2.859306573867798 Loss: 442.8252400863945\n",
      "Batch Complete: Time -2.878993272781372 Loss: 437.97846211229967\n",
      "Batch Complete: Time -2.8736698627471924 Loss: 438.43277359236106\n",
      "Batch Complete: Time -2.8102355003356934 Loss: 435.93695390920834\n",
      "Batch Complete: Time -2.8797104358673096 Loss: 442.06086651409964\n",
      "Batch Complete: Time -2.9310758113861084 Loss: 438.43464360876635\n",
      "Batch Complete: Time -2.863114833831787 Loss: 434.02710767697215\n",
      "Batch Complete: Time -2.802783966064453 Loss: 433.843347675632\n",
      "Batch Complete: Time -2.8157670497894287 Loss: 438.24775453135504\n",
      "Batch Complete: Time -2.958045482635498 Loss: 433.809299928627\n",
      "Batch Complete: Time -2.8653321266174316 Loss: 439.8535350264269\n",
      "Batch Complete: Time -2.837106943130493 Loss: 439.3783892428393\n",
      "Batch Complete: Time -2.999931573867798 Loss: 431.2703385842238\n",
      "Batch Complete: Time -2.8092424869537354 Loss: 433.9889285427433\n",
      "Batch Complete: Time -2.875471353530884 Loss: 431.19686878348955\n",
      "Batch Complete: Time -2.855512857437134 Loss: 426.73785075039945\n",
      "Batch Complete: Time -3.01399302482605 Loss: 428.9877905143941\n",
      "Batch Complete: Time -2.822038412094116 Loss: 431.38967145577834\n",
      "Batch Complete: Time -1.2964510917663574 Loss: 487.7947086543976\n",
      "Batch Complete: Time -3.0066540241241455 Loss: 431.7384259463883\n",
      "Batch Complete: Time -2.8734195232391357 Loss: 429.767711633384\n",
      "Batch Complete: Time -2.88901424407959 Loss: 434.15719323459666\n",
      "Batch Complete: Time -2.861262798309326 Loss: 429.04266036667934\n",
      "Batch Complete: Time -2.8462743759155273 Loss: 433.3459750185832\n",
      "Batch Complete: Time -2.8812735080718994 Loss: 431.6208113348355\n",
      "Batch Complete: Time -2.7786245346069336 Loss: 428.7369505999371\n",
      "Batch Complete: Time -2.9689011573791504 Loss: 430.0726537237084\n",
      "Batch Complete: Time -2.8744888305664062 Loss: 428.0795800056292\n",
      "Batch Complete: Time -2.913823127746582 Loss: 436.7367647889021\n",
      "Batch Complete: Time -2.8475160598754883 Loss: 423.8538234862822\n",
      "Batch Complete: Time -3.0027341842651367 Loss: 423.93920937105946\n",
      "Batch Complete: Time -2.878579616546631 Loss: 418.5478140513231\n",
      "Batch Complete: Time -2.9454596042633057 Loss: 421.4229852556429\n",
      "Batch Complete: Time -2.933490037918091 Loss: 423.5328155646914\n",
      "Batch Complete: Time -3.430180549621582 Loss: 416.74774321589007\n",
      "Batch Complete: Time -2.781511068344116 Loss: 413.4814923241543\n",
      "Batch Complete: Time -2.863553524017334 Loss: 410.78677880434446\n",
      "Batch Complete: Time -2.879922389984131 Loss: 413.75673537012426\n",
      "Batch Complete: Time -2.8621740341186523 Loss: 416.362243769591\n",
      "Batch Complete: Time -2.811615467071533 Loss: 417.19257405622136\n",
      "Batch Complete: Time -2.98366379737854 Loss: 414.3788399578616\n",
      "Batch Complete: Time -3.8472042083740234 Loss: 409.2086651579289\n",
      "Batch Complete: Time -4.193026781082153 Loss: 411.3529776939047\n",
      "Batch Complete: Time -2.9800586700439453 Loss: 410.16866758894844\n",
      "Batch Complete: Time -3.01128888130188 Loss: 405.05543391821215\n",
      "Batch Complete: Time -1.2772159576416016 Loss: 462.97902517453605\n",
      "Batch Complete: Time -2.9204444885253906 Loss: 402.577311412068\n",
      "Batch Complete: Time -3.515296697616577 Loss: 401.74601300234013\n",
      "Batch Complete: Time -7.406075954437256 Loss: 403.1974324995407\n",
      "Batch Complete: Time -9.42499589920044 Loss: 404.58310956657533\n",
      "Batch Complete: Time -4.876441478729248 Loss: 398.505505427014\n",
      "Batch Complete: Time -4.776789903640747 Loss: 401.46800966540275\n",
      "Batch Complete: Time -4.620871067047119 Loss: 401.82376248937777\n",
      "Batch Complete: Time -4.842665672302246 Loss: 396.2269593008381\n",
      "Batch Complete: Time -4.559590578079224 Loss: 404.82534615912846\n",
      "Batch Complete: Time -4.561027765274048 Loss: 398.1750371816148\n",
      "Batch Complete: Time -5.055896520614624 Loss: 392.03914310118313\n",
      "Batch Complete: Time -4.548830270767212 Loss: 394.26611530536627\n",
      "Batch Complete: Time -4.532652378082275 Loss: 398.0868098762923\n",
      "Batch Complete: Time -5.095437049865723 Loss: 397.0072599470498\n",
      "Batch Complete: Time -4.375956773757935 Loss: 394.9555158277335\n",
      "Batch Complete: Time -6.523365497589111 Loss: 391.1310852043281\n",
      "Batch Complete: Time -4.3968505859375 Loss: 389.36692219088496\n",
      "Batch Complete: Time -4.179023742675781 Loss: 389.82922630537587\n",
      "Batch Complete: Time -4.041069746017456 Loss: 393.89075226111487\n",
      "Batch Complete: Time -3.6551594734191895 Loss: 395.34774897780557\n",
      "Batch Complete: Time -3.758277177810669 Loss: 388.05662840132015\n",
      "Batch Complete: Time -3.5837337970733643 Loss: 387.22754990736826\n",
      "Batch Complete: Time -3.6140670776367188 Loss: 388.21368642414325\n",
      "Batch Complete: Time -3.641247510910034 Loss: 386.96335895519564\n",
      "Batch Complete: Time -4.131461143493652 Loss: 388.75876910252447\n",
      "Batch Complete: Time -4.284995794296265 Loss: 387.1492856146458\n",
      "Batch Complete: Time -2.7575244903564453 Loss: 453.2473947654278\n",
      "Batch Complete: Time -4.93734335899353 Loss: 376.6033475127512\n",
      "Batch Complete: Time -4.721313238143921 Loss: 386.0373895853904\n",
      "Batch Complete: Time -4.347827196121216 Loss: 395.5659632785557\n",
      "Batch Complete: Time -4.081758975982666 Loss: 395.22051454951554\n",
      "Batch Complete: Time -3.9683072566986084 Loss: 385.76119348924885\n",
      "Batch Complete: Time -3.9166345596313477 Loss: 389.1766259883387\n",
      "Batch Complete: Time -4.984713792800903 Loss: 390.4631328127958\n",
      "Batch Complete: Time -3.533430576324463 Loss: 386.44478674297426\n",
      "Batch Complete: Time -3.560804605484009 Loss: 391.642222450662\n",
      "Batch Complete: Time -4.080162763595581 Loss: 392.5738530624687\n",
      "Batch Complete: Time -3.262937307357788 Loss: 387.2525555369027\n",
      "Batch Complete: Time -3.25785756111145 Loss: 387.18773981626987\n",
      "Batch Complete: Time -3.5490708351135254 Loss: 386.2337632749663\n",
      "Batch Complete: Time -3.0756187438964844 Loss: 386.8369316323591\n",
      "Batch Complete: Time -3.1043033599853516 Loss: 389.7289142681402\n",
      "Batch Complete: Time -3.255650281906128 Loss: 379.49869170255886\n",
      "Batch Complete: Time -3.4167659282684326 Loss: 386.46051066575933\n",
      "Batch Complete: Time -3.255143165588379 Loss: 389.5551494262749\n",
      "Batch Complete: Time -3.245817184448242 Loss: 394.11027268951153\n",
      "Batch Complete: Time -3.158747434616089 Loss: 383.32531545565877\n",
      "Batch Complete: Time -3.3609893321990967 Loss: 387.72338139726304\n",
      "Batch Complete: Time -3.2274136543273926 Loss: 383.78302063462706\n",
      "Batch Complete: Time -3.312323808670044 Loss: 387.58138282353735\n",
      "Batch Complete: Time -3.250025510787964 Loss: 392.9443754753127\n",
      "Batch Complete: Time -5.362873077392578 Loss: 384.40798398470224\n",
      "Batch Complete: Time -4.707066774368286 Loss: 390.68994232253254\n",
      "Batch Complete: Time -2.0309793949127197 Loss: 448.6079997160127\n",
      "Batch Complete: Time -4.829074859619141 Loss: 388.906564933946\n",
      "Batch Complete: Time -5.026105642318726 Loss: 387.37387375869594\n",
      "Batch Complete: Time -6.2447075843811035 Loss: 378.0908223820015\n",
      "Batch Complete: Time -6.210072040557861 Loss: 392.1144133605684\n",
      "Batch Complete: Time -4.119073867797852 Loss: 388.7523904246721\n",
      "Batch Complete: Time -3.1041433811187744 Loss: 384.71296182093636\n",
      "Batch Complete: Time -2.92148494720459 Loss: 380.68814275434914\n",
      "Batch Complete: Time -4.26971173286438 Loss: 382.72751196881455\n",
      "Batch Complete: Time -3.3050153255462646 Loss: 386.1973874333245\n",
      "Batch Complete: Time -5.845114707946777 Loss: 388.5591450460881\n",
      "Batch Complete: Time -4.066460371017456 Loss: 383.6466563958062\n",
      "Batch Complete: Time -3.933908224105835 Loss: 380.56725128425165\n",
      "Batch Complete: Time -5.611794948577881 Loss: 383.2393992654574\n",
      "Batch Complete: Time -5.098634481430054 Loss: 390.17801268048413\n",
      "Batch Complete: Time -3.1959750652313232 Loss: 383.21142839392354\n",
      "Batch Complete: Time -3.5572969913482666 Loss: 387.59089869683436\n",
      "Batch Complete: Time -5.09624719619751 Loss: 387.95356824752884\n",
      "Batch Complete: Time -3.411531925201416 Loss: 385.3540039830034\n",
      "Batch Complete: Time -4.81130838394165 Loss: 387.8255577127146\n",
      "Batch Complete: Time -4.638349771499634 Loss: 387.00250852922585\n",
      "Batch Complete: Time -3.4648420810699463 Loss: 389.48955521508486\n",
      "Batch Complete: Time -6.889854907989502 Loss: 383.9638126677974\n",
      "Batch Complete: Time -7.15061616897583 Loss: 394.3728539497219\n",
      "Batch Complete: Time -5.450266361236572 Loss: 388.36367080730747\n",
      "Batch Complete: Time -4.7947142124176025 Loss: 383.65875214565614\n",
      "Batch Complete: Time -6.371498107910156 Loss: 386.3124441868756\n",
      "Batch Complete: Time -1.7095112800598145 Loss: 452.98661729493216\n",
      "Batch Complete: Time -5.864656686782837 Loss: 389.0083426093133\n",
      "Batch Complete: Time -3.3269660472869873 Loss: 384.7229199244514\n",
      "Batch Complete: Time -3.988051652908325 Loss: 383.2584807066564\n",
      "Batch Complete: Time -5.446377754211426 Loss: 386.9558484455844\n",
      "Batch Complete: Time -4.4499595165252686 Loss: 380.08616606138463\n",
      "Batch Complete: Time -5.912169456481934 Loss: 385.3794339967876\n",
      "Batch Complete: Time -3.0816476345062256 Loss: 389.2460878200272\n",
      "Batch Complete: Time -3.238612651824951 Loss: 384.1573582802559\n",
      "Batch Complete: Time -2.997333526611328 Loss: 384.4117251947946\n",
      "Batch Complete: Time -3.085689067840576 Loss: 388.39684115777186\n",
      "Batch Complete: Time -2.8215694427490234 Loss: 383.1621616844014\n",
      "Batch Complete: Time -3.0458128452301025 Loss: 381.0055744568169\n",
      "Batch Complete: Time -2.7879018783569336 Loss: 382.1390418008305\n",
      "Batch Complete: Time -2.8408823013305664 Loss: 389.6459068472736\n",
      "Batch Complete: Time -2.7923943996429443 Loss: 374.32600781562905\n",
      "Batch Complete: Time -2.842196464538574 Loss: 380.3997822565492\n",
      "Batch Complete: Time -2.7669827938079834 Loss: 388.1964349497629\n",
      "Batch Complete: Time -2.7971372604370117 Loss: 387.0954355857212\n",
      "Batch Complete: Time -3.7531578540802 Loss: 384.70154831180145\n",
      "Batch Complete: Time -5.332658290863037 Loss: 379.4892983708953\n",
      "Batch Complete: Time -3.9206693172454834 Loss: 382.90967740285396\n",
      "Batch Complete: Time -4.09620475769043 Loss: 388.95799890391794\n",
      "Batch Complete: Time -3.5707664489746094 Loss: 387.71945930689947\n",
      "Batch Complete: Time -3.119081735610962 Loss: 388.44425392068496\n",
      "Batch Complete: Time -3.10762357711792 Loss: 385.3368706417422\n",
      "Batch Complete: Time -4.101665735244751 Loss: 382.2220619710312\n",
      "Batch Complete: Time -1.7344942092895508 Loss: 434.52883496629977\n",
      "Batch Complete: Time -3.4221787452697754 Loss: 380.9882239060468\n",
      "Batch Complete: Time -3.9867897033691406 Loss: 381.4407079639598\n",
      "Batch Complete: Time -3.8292083740234375 Loss: 383.42748771377745\n",
      "Batch Complete: Time -4.075491905212402 Loss: 379.42866465071603\n",
      "Batch Complete: Time -4.250266075134277 Loss: 385.62188190113966\n",
      "Batch Complete: Time -3.662724733352661 Loss: 380.7535478970111\n",
      "Batch Complete: Time -3.6968934535980225 Loss: 384.81854983115926\n",
      "Batch Complete: Time -3.418910264968872 Loss: 385.6825394110803\n",
      "Batch Complete: Time -3.411893606185913 Loss: 389.37731337365904\n",
      "Batch Complete: Time -5.923617124557495 Loss: 377.3451383661987\n",
      "Batch Complete: Time -3.4496347904205322 Loss: 385.6587324917327\n",
      "Batch Complete: Time -4.679531574249268 Loss: 377.1828302667296\n",
      "Batch Complete: Time -3.7930657863616943 Loss: 384.6783796658659\n",
      "Batch Complete: Time -4.222732305526733 Loss: 381.6023064688495\n",
      "Batch Complete: Time -5.333636283874512 Loss: 382.72410991889296\n",
      "Batch Complete: Time -3.2027173042297363 Loss: 383.24837442728455\n",
      "Batch Complete: Time -4.64054799079895 Loss: 386.73549641713123\n",
      "Batch Complete: Time -3.821079969406128 Loss: 385.83844258742744\n",
      "Batch Complete: Time -3.391735076904297 Loss: 384.146216066887\n",
      "Batch Complete: Time -3.0289924144744873 Loss: 385.4541031238276\n",
      "Batch Complete: Time -3.001136302947998 Loss: 380.29024762233166\n",
      "Batch Complete: Time -2.9313602447509766 Loss: 376.31909570856726\n",
      "Batch Complete: Time -4.532235145568848 Loss: 383.9679346993656\n",
      "Batch Complete: Time -4.06055212020874 Loss: 380.61643484033664\n",
      "Batch Complete: Time -4.728557825088501 Loss: 373.2917423575113\n",
      "Batch Complete: Time -3.6286637783050537 Loss: 376.9099525305997\n",
      "Batch Complete: Time -2.1581685543060303 Loss: 438.19752890530617\n",
      "Batch Complete: Time -3.929551601409912 Loss: 378.8795227074822\n",
      "Batch Complete: Time -4.220912218093872 Loss: 379.2769208234932\n",
      "Batch Complete: Time -3.2171268463134766 Loss: 383.26333846680575\n",
      "Batch Complete: Time -3.208648681640625 Loss: 388.2972389682168\n",
      "Batch Complete: Time -3.6291089057922363 Loss: 374.56349509228494\n",
      "Batch Complete: Time -3.1867666244506836 Loss: 378.7944091067431\n",
      "Batch Complete: Time -3.2506279945373535 Loss: 376.5696907632176\n",
      "Batch Complete: Time -4.041229248046875 Loss: 369.86056481619994\n",
      "Batch Complete: Time -4.517172574996948 Loss: 383.9362660397942\n",
      "Batch Complete: Time -3.2126848697662354 Loss: 377.7243412329027\n",
      "Batch Complete: Time -3.1656394004821777 Loss: 379.95745088973734\n",
      "Batch Complete: Time -2.791177272796631 Loss: 377.5000931876206\n",
      "Batch Complete: Time -2.814633846282959 Loss: 384.60394267969997\n",
      "Batch Complete: Time -2.6397666931152344 Loss: 377.83203693424866\n",
      "Batch Complete: Time -4.554480314254761 Loss: 378.18422063882497\n",
      "Batch Complete: Time -4.897811412811279 Loss: 379.07777575043843\n",
      "Batch Complete: Time -6.19404411315918 Loss: 377.0881715661585\n",
      "Batch Complete: Time -4.529099225997925 Loss: 380.00909597163945\n",
      "Batch Complete: Time -3.7957942485809326 Loss: 379.8826185534146\n",
      "Batch Complete: Time -4.0962233543396 Loss: 373.9206789821698\n",
      "Batch Complete: Time -4.283672094345093 Loss: 382.6146526747027\n",
      "Batch Complete: Time -4.85716700553894 Loss: 379.7289975531893\n",
      "Batch Complete: Time -5.41284704208374 Loss: 379.7895823471278\n",
      "Batch Complete: Time -4.941099405288696 Loss: 384.59580863859105\n",
      "Batch Complete: Time -4.824442148208618 Loss: 370.1461060101344\n",
      "Batch Complete: Time -4.642102241516113 Loss: 371.4489097213566\n",
      "Batch Complete: Time -2.679780960083008 Loss: 427.2216934866236\n",
      "Batch Complete: Time -5.215102910995483 Loss: 376.68652163761635\n",
      "Batch Complete: Time -7.130656957626343 Loss: 381.0918407207953\n",
      "Batch Complete: Time -6.402371406555176 Loss: 375.50567054572286\n",
      "Batch Complete: Time -4.601165056228638 Loss: 377.07871408535846\n",
      "Batch Complete: Time -5.124136447906494 Loss: 373.8494502390611\n",
      "Batch Complete: Time -4.468282699584961 Loss: 377.25259386754516\n",
      "Batch Complete: Time -3.519155740737915 Loss: 374.54893681106483\n",
      "Batch Complete: Time -3.7903506755828857 Loss: 372.3630395399981\n",
      "Batch Complete: Time -4.001436948776245 Loss: 367.7473196414166\n",
      "Batch Complete: Time -3.6025445461273193 Loss: 381.1974342852113\n",
      "Batch Complete: Time -3.353746175765991 Loss: 374.16939884668096\n",
      "Batch Complete: Time -3.571610689163208 Loss: 370.48497349569703\n",
      "Batch Complete: Time -3.398136615753174 Loss: 369.2465053348374\n",
      "Batch Complete: Time -3.396448850631714 Loss: 368.0871988783445\n",
      "Batch Complete: Time -3.4038405418395996 Loss: 377.353234006549\n",
      "Batch Complete: Time -3.224705934524536 Loss: 363.9768153177309\n",
      "Batch Complete: Time -7.315006971359253 Loss: 374.4648717121231\n",
      "Batch Complete: Time -4.997884035110474 Loss: 364.59717743014846\n",
      "Batch Complete: Time -5.102362155914307 Loss: 373.96335724657285\n",
      "Batch Complete: Time -4.1496522426605225 Loss: 368.5718929959389\n",
      "Batch Complete: Time -6.714165210723877 Loss: 371.2355132532042\n",
      "Batch Complete: Time -4.775556802749634 Loss: 369.5218303478881\n",
      "Batch Complete: Time -5.1832404136657715 Loss: 371.90258397839426\n",
      "Batch Complete: Time -5.099988222122192 Loss: 367.8699663053585\n",
      "Batch Complete: Time -3.4968600273132324 Loss: 366.50207159742314\n",
      "Batch Complete: Time -4.728878974914551 Loss: 372.24499727543196\n",
      "Batch Complete: Time -2.8699185848236084 Loss: 422.23698149540445\n",
      "Batch Complete: Time -4.326398134231567 Loss: 370.124024390071\n",
      "Batch Complete: Time -5.203052759170532 Loss: 364.23770273431904\n",
      "Batch Complete: Time -4.1097753047943115 Loss: 361.0008014003113\n",
      "Batch Complete: Time -3.4818437099456787 Loss: 362.88703480685626\n",
      "Batch Complete: Time -3.8133814334869385 Loss: 365.7704466433213\n",
      "Batch Complete: Time -3.698822498321533 Loss: 370.60096689939024\n",
      "Batch Complete: Time -3.983116865158081 Loss: 364.2572195061047\n",
      "Batch Complete: Time -5.9520039558410645 Loss: 359.0559982567338\n",
      "Batch Complete: Time -4.406346559524536 Loss: 360.1260146457057\n",
      "Batch Complete: Time -3.7277565002441406 Loss: 360.41822203130585\n",
      "Batch Complete: Time -3.0445473194122314 Loss: 362.5037362167243\n",
      "Batch Complete: Time -3.512702703475952 Loss: 354.52390996470666\n",
      "Batch Complete: Time -2.7643001079559326 Loss: 361.715553022333\n",
      "Batch Complete: Time -3.127863883972168 Loss: 357.8522164968588\n",
      "Batch Complete: Time -2.7684431076049805 Loss: 353.70027397732537\n",
      "Batch Complete: Time -2.8261637687683105 Loss: 357.52556133507426\n",
      "Batch Complete: Time -3.130722999572754 Loss: 353.69241427863307\n",
      "Batch Complete: Time -2.7331197261810303 Loss: 354.79182364161363\n",
      "Batch Complete: Time -2.831948757171631 Loss: 348.6699921403127\n",
      "Batch Complete: Time -2.843867540359497 Loss: 350.9365694079645\n",
      "Batch Complete: Time -2.812190055847168 Loss: 348.03193412249595\n",
      "Batch Complete: Time -2.7506632804870605 Loss: 352.1972000899029\n",
      "Batch Complete: Time -2.805654525756836 Loss: 340.64315650428273\n",
      "Batch Complete: Time -2.6670823097229004 Loss: 338.194043240026\n",
      "Batch Complete: Time -3.381730556488037 Loss: 334.28869295584633\n",
      "Batch Complete: Time -3.444328784942627 Loss: 339.0000942477278\n",
      "Batch Complete: Time -1.2379329204559326 Loss: 401.71178342976964\n",
      "Batch Complete: Time -2.767794370651245 Loss: 334.11689849246665\n",
      "Batch Complete: Time -2.834010601043701 Loss: 335.0737285566033\n",
      "Batch Complete: Time -3.0215821266174316 Loss: 332.3885645665862\n",
      "Batch Complete: Time -3.0512311458587646 Loss: 336.6006896355506\n",
      "Batch Complete: Time -3.515669345855713 Loss: 332.44436815128944\n",
      "Batch Complete: Time -3.25894832611084 Loss: 331.2146870861034\n",
      "Batch Complete: Time -3.340711832046509 Loss: 338.61870000841475\n",
      "Batch Complete: Time -2.983384132385254 Loss: 340.4953779930777\n",
      "Batch Complete: Time -2.8751657009124756 Loss: 336.24834832225986\n",
      "Batch Complete: Time -2.6786727905273438 Loss: 338.52943086421703\n",
      "Batch Complete: Time -2.581773281097412 Loss: 334.21095822832496\n",
      "Batch Complete: Time -2.73544979095459 Loss: 335.61395051661475\n",
      "Batch Complete: Time -2.603790521621704 Loss: 333.80059957142583\n",
      "Batch Complete: Time -2.5981054306030273 Loss: 332.64548541965416\n",
      "Batch Complete: Time -2.6425204277038574 Loss: 329.0646556827787\n",
      "Batch Complete: Time -2.7103545665740967 Loss: 329.2338857044551\n",
      "Batch Complete: Time -2.5584964752197266 Loss: 335.28080214464546\n",
      "Batch Complete: Time -2.7096359729766846 Loss: 335.3089995843846\n",
      "Batch Complete: Time -2.6529054641723633 Loss: 327.3513792928544\n",
      "Batch Complete: Time -2.696126699447632 Loss: 336.4978697930342\n",
      "Batch Complete: Time -2.5938775539398193 Loss: 327.3120488785367\n",
      "Batch Complete: Time -2.66270112991333 Loss: 327.95645617375\n",
      "Batch Complete: Time -2.639380931854248 Loss: 328.80617883271043\n",
      "Batch Complete: Time -2.666522979736328 Loss: 327.6495386009687\n",
      "Batch Complete: Time -2.693892240524292 Loss: 328.0357966718972\n",
      "Batch Complete: Time -2.755056381225586 Loss: 331.17274657503435\n",
      "Batch Complete: Time -1.5260109901428223 Loss: 392.5345277385198\n",
      "Total Time 2738.249114513397\n"
     ]
    }
   ],
   "source": [
    "results = basic_train(model, crit, optimiser,\n",
    "                train_x, train_y, neurons,\n",
    "                epoches=30, batch=6, timestep=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7882f007-1dbd-4f38-b31d-fd31e4a74b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimiser.state_dict(),\n",
    "            }, \"checkpoints/ruby/modellr001dt01.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b06ff-0560-45ca-a4ba-bba121fb3a02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
